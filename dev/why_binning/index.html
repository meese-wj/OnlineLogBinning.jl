<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Why use a Binning Analysis? · OnlineLogBinning.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://meese-wj.github.io/OnlineLogBinning.jl/why_binning/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">OnlineLogBinning.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Why use a Binning Analysis?</a><ul class="internal"><li><a class="tocitem" href="#Theoretical-background"><span>Theoretical background</span></a></li><li><a class="tocitem" href="#Visualizing-a-Binning-Analysis"><span>Visualizing a Binning Analysis</span></a></li></ul></li><li><a class="tocitem" href="../accumulators/">Accumulator Hierarchy</a></li><li><a class="tocitem" href="../example/">Example Usage</a></li><li><a class="tocitem" href="../math/">Mathematical Details</a></li><li><a class="tocitem" href="../related_packages/">Related Packages</a></li><li><a class="tocitem" href="../api/">API Reference</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Why use a Binning Analysis?</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Why use a Binning Analysis?</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/meese-wj/OnlineLogBinning.jl/blob/main/docs/src/why_binning.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Why-use-a-Binning-Analysis?"><a class="docs-heading-anchor" href="#Why-use-a-Binning-Analysis?">Why use a Binning Analysis?</a><a id="Why-use-a-Binning-Analysis?-1"></a><a class="docs-heading-anchor-permalink" href="#Why-use-a-Binning-Analysis?" title="Permalink"></a></h1><p>As described in <a href="../references/#Wallerberger2019">Markus Wallerberger (2019)</a>, <a href="../references/#AmbegaokarTroyerEstimatingErrors">Vinay Ambegaokar, Matthias Troyer (2010)</a>, <a href="../references/#ChanGolubLeVequeSandT">Tony F. Chan, Gene H. Golub, Randall J. LeVeque (1983)</a>, <a href="../references/#BauerThesis">Carsten Bauer (2020)</a>, and <a href="../references/#GubernatisKawashimaWerner">James Gubernatis, Naoki Kawashima, Philipp Werner (2016)</a>, the presence of correlations in a data stream generated in Markov Chain Monte Carlo simulations renders any measures of error severely underestimated.</p><h2 id="Theoretical-background"><a class="docs-heading-anchor" href="#Theoretical-background">Theoretical background</a><a id="Theoretical-background-1"></a><a class="docs-heading-anchor-permalink" href="#Theoretical-background" title="Permalink"></a></h2><p>The naive approach is to calculate the <code>mean</code> and the variance of the mean, <code>var_of_mean</code>, for a given data stream <span>$X$</span>. For uncorrelated data, this becomes</p><p class="math-container">\[\begin{aligned}
\mathtt{mean}(X) &amp;= \frac{1}{M} \sum_{i = 1}^M x_i
\\
\mathtt{var\_of\_mean}(X) &amp;= \frac{1}{M(M-1)} \sum_{i = 1}^M (x_i - \mathtt{mean}(X))^2.
\end{aligned}\]</p><p>Fortunately, in the presence of correlations, the <code>mean</code> doesn&#39;t change. Unfortunately, the <code>var_of_mean</code> does. Indeed, one can show that it&#39;s given by</p><p class="math-container">\[\mathtt{var\_of\_mean}(X) = \frac{1 + 2\tau_X}{M(M-1)} \sum_{i = 1}^M (x_i - \mathtt{mean}(X))^2,\]</p><p>where the as shown in the Figure within the <a href="../accumulators/#Accumulator-type-hierarchy"><code>Accumulator</code> type hierarchy</a>. Clearly, the uncorrelated <code>var_of_mean</code> is just increased by a factor of <span>$R_X \equiv 1 + 2\tau_X$</span>, where <span>$\tau_X$</span> is defined as the <em>integrated</em> <a href="../api/#OnlineLogBinning.autocorrelation_time-Tuple{Any}"><code>autocorrelation_time</code></a> of the data stream. The binning analysis provides a <em>fast</em> as an <code>O(N)</code> method for calculating the <a href="../api/#OnlineLogBinning.autocorrelation_time-Tuple{Any}"><code>autocorrelation_time</code></a>. It&#39;s also <em>cheap</em>, only requiring <code>O(log N)</code> in RAM.  For those who are unfamiliar with the term, normally one would calculate <span>$\tau_X$</span> by</p><p class="math-container">\[\tau_X = \sum_{i = 1}^M \sum_{i &lt; j} \left[ x_ix_j - \mathtt{mean}(x)^2 \right],\]</p><p>which is an  <code>O(N^2)</code> summation and can suffer from numerical instabilities.</p><p>As one performs pairwise means in each binning level to construct the next highest, and then calculates the <code>var_of_mean</code> for each level, one can see that it rises and then eventually saturates around a particular <code>plateau</code> value. Normalizing by the original <code>var_of_mean</code> calculation <em>assuming</em> the data stream is <em>uncorrelated</em>, one can then calculate <span>$R_X$</span> in the <span>$\ell^{\rm th}$</span> binning level as</p><p class="math-container">\[R_X(\ell) = \frac{\mathtt{var\_of\_mean}(X^{(\ell)})}{\mathtt{var\_of\_mean}(X^{(0)})} = \frac{ m^{(\ell)} \mathtt{var}(X^{(\ell)}) }{ \mathtt{var}(X^{(0)}) },\]</p><p>where <code>var</code> is the normal variance and <span>$m^{(\ell)}$</span> is the <em>bin size</em>, or the number of original data values accumulated into a single data point at the <span>$\ell^{\rm th}$</span> level.</p><h2 id="Visualizing-a-Binning-Analysis"><a class="docs-heading-anchor" href="#Visualizing-a-Binning-Analysis">Visualizing a Binning Analysis</a><a id="Visualizing-a-Binning-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-a-Binning-Analysis" title="Permalink"></a></h2><p>The final result of the binning analysis, for sufficiently long data streams, will be to see a <a href="../api/#OnlineLogBinning.sigmoid"><code>sigmoid</code></a>-like curve. We&#39;ve wrapped up a fitting and plotting workflow into the <code>plot_binning_analysis</code> function below to demonstrate how it works. Feel free to skip over to the <a href="#Visualization-Examples">Visualization Examples</a> if you have your own workflow established.</p><pre><code class="language- hljs">using OnlineLogBinning, Plots, LaTeXStrings
pyplot()

# Return the fitted inflection point
sigmoid_inflection(fit) = fit.param[2] / fit.param[3]

# Define a plotting function with Plots.jl
# This function plots the RxValues, the Sigmoid fit,
# the maximum trustworthy level, and the fitted 
# inflection point.
function plot_binning_analysis(bacc)
    # Plot the RxValues irrespective of the trusting cutoff
    all_levels, all_rxvals = levels_RxValues(bacc, false)
    plt = plot( all_levels, all_rxvals; 
                label = &quot;Binning Analysis&quot;,
                xlabel = L&quot;Bin Level $\ell$&quot;,
                ylabel = L&quot;$R_X(\ell)$&quot;,
                markershape = :circle,
                legend = :topleft )

    # Fit only the trustworthy levels
    levels, rxvals = levels_RxValues(bacc)
    fit = fit_RxValues(levels, rxvals)

    # Plot the sigmoid fit
    plot!(plt, all_levels, sigmoid(all_levels, fit.param);
          label = &quot;Sigmoid Fit&quot;)

    # Plot the maximum trustworthy level
    vline!(plt, [ max_trustworthy_level(bacc[level = 0].num_bins) ];
           ls = :dash, color = &quot;gray&quot;, 
           label = &quot;Maximum Trustworthy Level&quot;)

    # Plot the fitted inflection point if it&#39;s positive
    if sigmoid_inflection(fit) &gt; zero(fit.param[2])
        vline!(plt, [ sigmoid_inflection(fit) ];
               ls = :dot, color = &quot;red&quot;, 
               label = &quot;Sigmoid Inflection Point&quot;)
    end
    return plt
end

nothing # hide</code></pre><h3 id="Visualization-Examples"><a class="docs-heading-anchor" href="#Visualization-Examples">Visualization Examples</a><a id="Visualization-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization-Examples" title="Permalink"></a></h3><p>Now we demonstrate four cases that tend to appear with binning analyses:</p><ol><li>The binning analysis converges to a plateau for a correlated data stream <a href="#example_plot_1"><span>$R_X(\ell \rightarrow \infty) &gt; 0$</span></a>.</li><li>The binning analysis reveals that the data stream is truly <em>uncorrelated</em> <a href="#example_plot_2"><span>$R_X(\ell \rightarrow \infty) = 0$</span></a>.</li><li>The binning analysis has <a href="#example_plot_3">not converged</a> because too few data were taken in the data stream to isolate the uncorrelated data.</li><li>The binning analyis has not convered because all of the data in the data stream are more-or-less <a href="#example_plot_4"><em>equally</em> correlated</a>.</li></ol><p>The first two cases are ideal. They represent situations where the data stream has enough data to distinguish correlated blocks from one another. In these first two cases, the <a href="../api/#OnlineLogBinning.BinningAnalysisResult"><code>BinningAnalysisResult</code></a> will yield <code>plateau_found == true</code>.</p><p>The second two cases are not so ideal. Either way they show that the correlations in the data stream are so strong that individual uncorrelated blocks can not be robustly created and more sampling is required. Therefore, their <a href="../api/#OnlineLogBinning.BinningAnalysisResult"><code>BinningAnalysisResult</code></a> yields <code>plateau_found == false</code>.</p><p>The data shown are pre-simulated signals generated by the <a href="https://meese-wj.github.io/TelegraphNoise.jl/dev/"><code>TelegraphNoise.jl</code></a> package (<code>v0.1.0</code>). <em>Random telegraph signals</em> have an analytically-defined autocorrelation time <span>$\tau_X$</span> related to their average dwell time <span>$T_D$</span> by <span>$\tau_X = T_D / 2$</span>. Since the signals are random, they are saved previously, but I&#39;ll provide each chosen <span>$T_D$</span> for reproducibility purposes.</p><h4 id="example_plot_1"><a class="docs-heading-anchor" href="#example_plot_1">Example 1: Clear <span>$R_X$</span> plateau at a finite value</a><a id="example_plot_1-1"></a><a class="docs-heading-anchor-permalink" href="#example_plot_1" title="Permalink"></a></h4><p>This first case shows the textbook (<a href="../references/#GubernatisKawashimaWerner">James Gubernatis, Naoki Kawashima, Philipp Werner (2016)</a>) example of an <span>$R_X$</span> plateau found in a binning analysis. The dwell time for this signal was chosen to be <span>$T_D = 16$</span>, meaning <span>$\tau_X = 8$</span>, and the signal generated was <span>$2^{18} = 262144$</span> in length.</p><pre><code class="language- hljs">
# Read in pre-simulated TelegraphNoise.jl data with a plateau
signal = zeros(Float64, Int(2^18))
read!( joinpath(&quot;assets&quot;, &quot;telegraph_plateau.bin&quot;), signal )
bacc = BinningAccumulator()
push!(bacc, signal)

plot_binning_analysis(bacc)</code></pre><pre><code class="language-julia hljs">result = fit_RxValues(bacc)
result.plateau_found

# output

true</code></pre><p>Importantly, note that the fitted inflection point is greater than zero, but less than the maximum trustworthy level. The variations in the calculated <span>$R_X$</span> values for <span>$\ell$</span> greater than the maximum trustworthy level are due to strong fluctuations because of small number statistics.</p><h4 id="example_plot_2"><a class="docs-heading-anchor" href="#example_plot_2">Example 2: Uncorrelated data ~ <span>$R_X(\ell \rightarrow \infty) = 0$</span></a><a id="example_plot_2-1"></a><a class="docs-heading-anchor-permalink" href="#example_plot_2" title="Permalink"></a></h4><p>The dwell time for this signal was chosen to be <span>$T_D = 1/2$</span>, meaning <span>$\tau_X = 1/4$</span>, and the signal generated was <span>$2^{14} = 16384$</span> in length.</p><pre><code class="language- hljs">
# Read in pre-simulated TelegraphNoise.jl data with a plateau
signal = zeros(Float64, Int(2^14))
read!( joinpath(&quot;assets&quot;, &quot;telegraph_uncorrelated.bin&quot;), signal )
bacc = BinningAccumulator()
push!(bacc, signal)

plot_binning_analysis(bacc)</code></pre><pre><code class="language-julia hljs">result = fit_RxValues(bacc)
result.plateau_found

# output

true</code></pre><p>Notice that the <span>$R_X$</span> values decay for increasing <span>$\ell$</span>. This is because the binning analysis cannot detect any smaller blocks of uncorrelated data since the original data stream is indeed correlated.</p><h4 id="example_plot_3"><a class="docs-heading-anchor" href="#example_plot_3">Example 3: No plateau due to data insufficiency</a><a id="example_plot_3-1"></a><a class="docs-heading-anchor-permalink" href="#example_plot_3" title="Permalink"></a></h4><p>For insufficiently long data streams, we do not expect a plateau, as shown in the following case:</p><pre><code class="language- hljs">
# Read in pre-simulated TelegraphNoise.jl data without a plateau
signal = zeros(Float64, Int(2^10))
read!( joinpath(&quot;assets&quot;, &quot;telegraph_no_plateau.bin&quot;), signal )
bacc = BinningAccumulator()
push!(bacc, signal)

plot_binning_analysis(bacc)</code></pre><pre><code class="language-julia hljs">result = fit_RxValues(bacc)
result.plateau_found

# output

false</code></pre><p>Here, the dwell time was chosen to be <span>$T_D = 256$</span>, meaning <span>$\tau_X = 128$</span>, and the signal generated was <span>$2^{10} = 1024$</span> in length. Notice, that the binning analysis began to pick up on a set of uncorrelated blocks, but there was not enough simulated data to reveal them before the maximum trustworthy level was reached. In a case like this, one would simply need to run their simulation about <em>64</em> times longer reveal a fitted plateau.</p><h4 id="example_plot_4"><a class="docs-heading-anchor" href="#example_plot_4">Example 4: No plateau due to totally-correlated data</a><a id="example_plot_4-1"></a><a class="docs-heading-anchor-permalink" href="#example_plot_4" title="Permalink"></a></h4><p>In this final example, we demonstrate what happens for a data stream that has &quot;frozen-in&quot; correlations. By this, we mean one where the autocorrelation time <span>$\tau_X$</span> far exceeds the data stream size. For this case, <span>$T_D = 2^{16} = 65536$</span>, so <span>$\tau_X = 2^{15} = 32768$</span>, while the signal length is only <span>$2^{12} = 4096$</span>.</p><pre><code class="language- hljs">
# Read in pre-simulated TelegraphNoise.jl data with a plateau
signal = zeros(Float64, Int(2^12))
read!( joinpath(&quot;assets&quot;, &quot;telegraph_totally_correlated.bin&quot;), signal )
bacc = BinningAccumulator()
push!(bacc, signal)

plot_binning_analysis(bacc)</code></pre><pre><code class="language-julia hljs">result = fit_RxValues(bacc)
result.plateau_found

# output

false</code></pre><p>In this case, eventually the binning analysis returns <span>$R_X = 0$</span>, since the blocks start comparing literally identical elements. Notice that this case would return a <code>plateau_found</code> if it were not for the check if any of the <span>$R_X$</span> values were too small. (In principle this case also would result from a data stream with a defined periodicity, despite having correlations, but this is unavoidable.)</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>This is the most dangerous case to automate because the <a href="../api/#Statistics.var-Tuple{BinningAccumulator}"><code>var</code></a>iance of such a data stream is naturally very small relative to the <a href="../api/#Statistics.mean-Tuple{BinningAccumulator}"><code>mean</code></a>. As is the case with all Monte Carlo simulations, or statistical data streams, one should be <em>very</em> wary when the error is a mathematical zero, or vanishingly small compared to the calculated <a href="../api/#Statistics.mean-Tuple{BinningAccumulator}"><code>mean</code></a>.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../accumulators/">Accumulator Hierarchy »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Wednesday 29 March 2023 00:49">Wednesday 29 March 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
